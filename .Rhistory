e1<-residuals(fit1)
x<-auto$cyl
plot(x, e1, xlab = "Number of Cylinders", ylab = "Residuals (MPG)", bg="lightblue", col="black", cex=2, pch=21, frame=FALSE)
abline(h=0, lwd=2)
for(i in 1:n)
lines(c(x[i],x[i]),c(e1[i],0),col="red",lwd=2)
e2<-residuals(fit2)
x<-auto$cyl
plot(x, e2, xlab = "Number of Cylinders", ylab = "Residuals (MPG)", bg="lightblue", col="black", cex=2, pch=21, frame=FALSE)
abline(h=0, lwd=2)
for(i in 1:n)
lines(c(x[i],x[i]),c(e2[i],0),col="red",lwd=2)
?plot
e1<-residuals(fit1)
x<-auto$cyl
plot(x, e1, main="fit1 - Residual plot", xlab = "Number of Cylinders", ylab = "Residuals (MPG)", bg="lightblue", col="black", cex=2, pch=21, frame=FALSE)
abline(h=0, lwd=2)
for(i in 1:n)
lines(c(x[i],x[i]),c(e1[i],0),col="red",lwd=2)
# Now plot residuals for the fit2
e2<-residuals(fit2)
x<-auto$cyl
plot(x, e2, main="fit1 - Residual plot", xlab = "Number of Cylinders", ylab = "Residuals (MPG)", bg="lightblue", col="black", cex=2, pch=21, frame=FALSE)
abline(h=0, lwd=2)
for(i in 1:n)
lines(c(x[i],x[i]),c(e2[i],0),col="red",lwd=2)
e2<-residuals(fit2)
x<-auto$cyl
plot(x, e2, main="fit1 - Residual plot", xlab = "Number of Cylinders", ylab = "Residuals (MPG)", bg="lightblue", col="black", cex=2, pch=21, frame=FALSE)
abline(h=0, lwd=2)
for(i in 1:n)
lines(c(x[i],x[i]),c(e2[i],0),col="red",lwd=2)
data("diamond")
head(diamond)
max(abs(e1-e2))
y<-diamond$price
x<-diamond$carat
n<-length(y)
fit<-lm(y~x)
e1<-resid(fit) # Residuals calculated automatically by lm function of R
sigma<-summary(fit)$sigma # Residual standard deviation
sigma_squared<-sigma^2 # Residual variance
yhat<-predict(fit)
e2<-y-yhat # Residuals calculated manually here
max(abs(e1-e2)) #  Compare e1 and e2 for sanity check
max(abs(e1-(y-coef(fit)[1]-coef(fit)[2]*x))) # Another sanity check by manual calculation of yhat
sum(e1) # Let's see sum of residuals
sum(e1*x) #
plot(diamond$carat,diamond$price,xlab = "Mass (carat)",ylab = "Price (SIN$)",bg="lightblue",col="black",cex=1.1,pch=21,frame=FALSE)
abline(fit,lwd=2)
for(i in 1:n)
lines(c(x[i],x[i]),c(y[i],yhat[i]),col="red",lwd=2)
plot(x,e1,xlab = "Mass (carat)",ylab = "Residuals (SIN$)",bg="lightblue",col="black",cex=2, pch=21,frame=FALSE)
abline(h=0,lwd=2)
for(i in 1:n)
lines(c(x[i],x[i]),c(e1[i],0),col="red",lwd=2)
x=runif(100,-3,3)
y=x+sin(x)+rnorm(100,sd=0.2)
g=ggplot(data.frame(x=x,y=y),aes(x=x,y=y))
g=g+geom_smooth(method = "lm",colour="black")
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g
g=ggplot(data.frame(x=x,y=resid(lm(y~x))),aes(x=x,y=y))
g=g+geom_hline(yintercept = 0,size=2)
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g=g+xlab("X")+ylab("Residuals")
g
e1<-resid(lm(price~1, data = diamond)) # variation around the average price
e2<-resid(lm(price~carat, data = diamond)) # variation around the regression line with carats as the explanatory variable
e=c(e1, e2)
rep1<-rep("Itc",nrow(diamond))
rep2<-rep("Itc, slope", nrow(diamond))
fit=factor(c(rep1,rep2)) # this labels the set of residuals as Intercept only and Intercept with Slope
g=ggplot(data.frame(e=e,fit=fit), aes(y=e,x=fit, fill=fit))
g=g+geom_dotplot(binaxis = "y", size=2, stackdir = "center", binwidth = NULL)
g=g+xlab("Fitting approach")
g=g+ylab("Residual price")
g
x=runif(100,0,6)
y=x+rnorm(100, mean=0, sd=0.01*x) # data with heteroskedasticity, sd makes this happen.
g=ggplot(data.frame(x=x,y=y),aes(x=x,y=y))
g=g+geom_smooth(method = "lm",colour="black")
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g
g=ggplot(data.frame(x=x,y=resid(lm(y~x))),aes(x=x,y=y))
g=g+geom_hline(yintercept = 0,size=2)
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g=g+xlab("X")+ylab("Residuals")
g
# Let's first plot residuals for fit1
e1<-residuals(fit1)
x<-auto$cyl
plot(x, e1, main="fit1 - Residual plot", xlab = "Number of Cylinders", ylab = "Residuals (MPG)", bg="lightblue", col="black", cex=2, pch=21, frame=FALSE)
abline(h=0, lwd=2)
for(i in 1:n)
lines(c(x[i],x[i]),c(e1[i],0),col="red",lwd=2)
# Now plot residuals for the fit2
e2<-residuals(fit2)
x<-auto$cyl
plot(x, e2, main="fit2 - Residual plot", xlab = "Number of Cylinders", ylab = "Residuals (MPG)", bg="lightblue", col="black", cex=2, pch=21, frame=FALSE)
abline(h=0, lwd=2)
for(i in 1:n)
lines(c(x[i],x[i]),c(e2[i],0),col="red",lwd=2)
# Compare e1 and e2
max(abs(e1-e2))
library(knitr)
library(knitr)
# Let's first plot residuals for fit1
e1<-residuals(fit1)
x<-auto$cyl
plot(x, e1, main="fit1 - Residual plot", xlab = "Number of Cylinders", ylab = "Residuals (MPG)", bg="lightblue", col="black", cex=2, pch=21, frame=FALSE)
abline(h=0, lwd=2)
for(i in 1:n)
lines(c(x[i],x[i]),c(e1[i],0),col="red",lwd=2)
# Now plot residuals for the fit2
e2<-residuals(fit2)
x<-auto$cyl
plot(x, e2, main="fit2 - Residual plot", xlab = "Number of Cylinders", ylab = "Residuals (MPG)", bg="lightblue", col="black", cex=2, pch=21, frame=FALSE)
abline(h=0, lwd=2)
for(i in 1:n)
lines(c(x[i],x[i]),c(e2[i],0),col="red",lwd=2)
e1<-residuals(fit1)
x<-auto$cyl
g=ggplot(data.frame(x=x,y=e1),aes(x=x,y=y))
suppressMessages(library(UsingR))
suppressMessages(library(ggplot2))
suppressMessages(library(stats))
suppressMessages(library(dplyr))
data("mtcars")
g=ggplot(data.frame(x=x,y=e1),aes(x=x,y=y))
g=g+geom_hline(yintercept = 0,size=2)
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g=g+xlab("X")+ylab("Residuals")
g
e1<-residuals(fit1)
x<-auto$cyl
g=ggplot(data.frame(x=x,y=e1),aes(x=x,y=y))
g=g+geom_hline(yintercept = 0,size=2)
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g=g+xlab("X")+ylab("Residuals")
g
?ggplot
g=ggplot(data.frame(x=x,y=e1),aes(x=x,y=y))
g=g+geom_hline(yintercept = 0,size=2)
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g=g+ggtitle("fit1 - Residual plot")+xlab("X")+ylab("Residuals")
g
e1<-resid(lm(price~1, data = diamond)) # variation around the average price
e2<-resid(lm(price~carat, data = diamond)) # variation around the regression line with carats as the explanatory variable
e=c(e1, e2)
rep1<-rep("Itc",nrow(diamond))
rep2<-rep("Itc, slope", nrow(diamond))
fit=factor(c(rep1,rep2)) # this labels the set of residuals as Intercept only and Intercept with Slope
g=ggplot(data.frame(e=e,fit=fit), aes(y=e,x=fit, fill=fit))
g=g+geom_dotplot(binaxis = "y", size=2, stackdir = "center", binwidth = NULL)
g=g+xlab("Fitting approach")
g=g+ylab("Residual price")
g
cor(mtcars, use = "complete.obs", method = "kendall")
pairs(mpg~.,data = mtcars)
suppressMessages(library(UsingR))
suppressMessages(library(ggplot2))
suppressMessages(library(stats))
suppressMessages(library(dplyr))
data("mtcars")
# Let's first quickly read about mtcars data on R help
?mtcars
# Let's see the first six rows of the data
head(mtcars)
# Now let's look at the variables names of the data
names(mtcars)
# Now see more details about data as to its number of observations, number of variables, and the class of each variable
str(mtcars)
# Now let's see summary descriptive statistics on variable "mpg"
summary(mtcars$mpg)
# Now let's count how many of all 32 cars are with automatic transmission and how many are with manual
table(mtcars$am)
# Now let's see average MPG on automatic transmission cars and manual transmission cars separately
auto<-subset(mtcars, mtcars$am==0)
summary(auto$mpg)
manual<-subset(mtcars, mtcars$am==1)
summary(manual$mpg)
# Now let's see how many cylinder types we have in this data type
table(mtcars$cyl)
# 1. Let's fit models to data set of only automatic transmission cars
# 1.1 MPG as an outcome and number of cylinders as a predictor variable
fit1<-lm(mpg~factor(cyl) -1, data = auto)
summary(fit1)$coef
summarise(group_by(auto, cyl), meanMPG=mean(mpg))
# 1.2 MPG as an outcome, number of cylinders and weight as predictor variables
fit2<-lm(mpg~factor(cyl)+wt -1, data = auto)
summary(fit2)$coef
# 2. Now let's fit models to data set with manual transmission cars
# 2.1 MPG as an outcome and number of cylinders as a predictor variable
fit3<-lm(mpg~factor(cyl) -1, data = manual)
summary(fit3)$coef
summarise(group_by(manual, cyl), meanMPG=mean(mpg))
# 2.2 MPG as an outcome, number of cylinders and weight as predictor variables
fit4<-lm(mpg~factor(cyl)+wt -1, data = manual)
summary(fit4)$coef
anova(fit1, fit2)
library(knitr)
# Let's first plot residuals for fit1
e1<-residuals(fit1)
x<-auto$cyl
g=ggplot(data.frame(x=x,y=e1),aes(x=x,y=y))
g=g+geom_hline(yintercept = 0,size=2)
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g=g+ggtitle("fit1 - Residual plot")+xlab("X")+ylab("Residuals")
g
# Now plot residuals for the fit2
e2<-residuals(fit2)
x<-auto$cyl
g=ggplot(data.frame(x=x,y=e2),aes(x=x,y=y))
g=g+geom_hline(yintercept = 0,size=2)
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g=g+ggtitle("fit2 - Residual plot")+xlab("X")+ylab("Residuals")
g
# Compare e1 and e2
max(abs(e1-e2))
anova(fit3, fit4)
# Let's first plot residuals for fit3
e3<-residuals(fit3)
x<-manual$cyl
g=ggplot(data.frame(x=x,y=e3),aes(x=x,y=y))
g=g+geom_hline(yintercept = 0,size=2)
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g=g+ggtitle("fit3 - Residual plot")+xlab("X")+ylab("Residuals")
g
# Now plot residuals for the fit4
e4<-residuals(fit4)
x<-manual$cyl
g=ggplot(data.frame(x=x,y=e4),aes(x=x,y=y))
g=g+geom_hline(yintercept = 0,size=2)
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g=g+ggtitle("fit4 - Residual plot")+xlab("X")+ylab("Residuals")
g
# Compare e2 and e4
max(abs(e3-e4))
# Let's first create a test data for 10 cars
tcyl<-c(4,6,8,8,6,4,4,6,8,6)
twt<-runif(10,1.513,5.424)
ndata<-data.frame(cyl=tcyl, wt=twt)
# Predict with model 1
p1<-predict(fit1, newdata = ndata, interval = "prediction")
# Predict with model 2
p2<-predict(fit2, newdata = ndata, interval = "prediction")
# Predict with model 3
p3<-predict(fit3, newdata = ndata, interval = "prediction")
# Predict with model 4
p4<-predict(fit4, newdata = ndata, interval = "prediction")
# Compare predictions
prds<-data.frame(p1=p1, p2=p2, p3=p3, p4=p4)
fits<-data.frame(p1=mean(prds$p1.fit),p2=mean(prds$p2.fit),p3=mean(prds$p3.fit),p4=mean(prds$p4.fit))
lwrs<-data.frame(p1=mean(prds$p1.lwr),p2=mean(prds$p2.lwr),p3=mean(prds$p3.lwr),p4=mean(prds$p4.lwr))
uprs<-data.frame(p1=mean(prds$p1.upr),p2=mean(prds$p2.upr),p3=mean(prds$p3.upr),p4=mean(prds$p4.upr))
ovrl<-rbind(fits, lwrs, uprs)
row.names(ovrl)<-c("fits", "lwr", "upr")
ovrl
cor(mtcars,use = "complete.obs", method = "kendall")
pairs(mpg~.,data = mtcars)
suppressMessages(library(UsingR))
suppressMessages(library(ggplot2))
suppressMessages(library(stats))
suppressMessages(library(dplyr))
data("mtcars")
# Let's first quickly read about mtcars data on R help
?mtcars
# Let's see the first six rows of the data
head(mtcars)
# Now let's look at the variables names of the data
names(mtcars)
# Now see more details about data as to its number of observations, number of variables, and the class of each variable
str(mtcars)
# Now let's see summary descriptive statistics on variable "mpg"
summary(mtcars$mpg)
# Now let's count how many of all 32 cars are with automatic transmission and how many are with manual
table(mtcars$am)
# Now let's see average MPG on automatic transmission cars and manual transmission cars separately
auto<-subset(mtcars, mtcars$am==0)
summary(auto$mpg)
manual<-subset(mtcars, mtcars$am==1)
summary(manual$mpg)
# Now let's see how many cylinder types we have in this data type
table(mtcars$cyl)
# 1. Let's fit models to data set of only automatic transmission cars
# 1.1 MPG as an outcome and number of cylinders as a predictor variable
fit1<-lm(mpg~factor(cyl) -1, data = auto)
summary(fit1)$coef
summarise(group_by(auto, cyl), meanMPG=mean(mpg))
# 1.2 MPG as an outcome, number of cylinders and weight as predictor variables
fit2<-lm(mpg~factor(cyl)+wt -1, data = auto)
summary(fit2)$coef
# 2. Now let's fit models to data set with manual transmission cars
# 2.1 MPG as an outcome and number of cylinders as a predictor variable
fit3<-lm(mpg~factor(cyl) -1, data = manual)
summary(fit3)$coef
summarise(group_by(manual, cyl), meanMPG=mean(mpg))
# 2.2 MPG as an outcome, number of cylinders and weight as predictor variables
fit4<-lm(mpg~factor(cyl)+wt -1, data = manual)
summary(fit4)$coef
anova(fit1, fit2)
library(knitr)
# Let's first plot residuals for fit1
e1<-residuals(fit1)
x<-auto$cyl
g=ggplot(data.frame(x=x,y=e1),aes(x=x,y=y))
g=g+geom_hline(yintercept = 0,size=2)
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g=g+ggtitle("fit1 - Residual plot")+xlab("X")+ylab("Residuals")
g
# Now plot residuals for the fit2
e2<-residuals(fit2)
x<-auto$cyl
g=ggplot(data.frame(x=x,y=e2),aes(x=x,y=y))
g=g+geom_hline(yintercept = 0,size=2)
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g=g+ggtitle("fit2 - Residual plot")+xlab("X")+ylab("Residuals")
g
# Compare e1 and e2
max(abs(e1-e2))
anova(fit3, fit4)
# Let's first plot residuals for fit3
e3<-residuals(fit3)
x<-manual$cyl
g=ggplot(data.frame(x=x,y=e3),aes(x=x,y=y))
g=g+geom_hline(yintercept = 0,size=2)
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g=g+ggtitle("fit3 - Residual plot")+xlab("X")+ylab("Residuals")
g
# Now plot residuals for the fit4
e4<-residuals(fit4)
x<-manual$cyl
g=ggplot(data.frame(x=x,y=e4),aes(x=x,y=y))
g=g+geom_hline(yintercept = 0,size=2)
g=g+geom_point(size=7,colour="black",alpha=0.4)
g=g+geom_point(size=5,colour="red",alpha=0.4)
g=g+ggtitle("fit4 - Residual plot")+xlab("X")+ylab("Residuals")
g
# Compare e2 and e4
max(abs(e3-e4))
# Let's first create a test data for 10 cars
tcyl<-c(4,6,8,8,6,4,4,6,8,6)
twt<-runif(10,1.513,5.424)
ndata<-data.frame(cyl=tcyl, wt=twt)
# Predict with model 1
p1<-predict(fit1, newdata = ndata, interval = "prediction")
# Predict with model 2
p2<-predict(fit2, newdata = ndata, interval = "prediction")
# Predict with model 3
p3<-predict(fit3, newdata = ndata, interval = "prediction")
# Predict with model 4
p4<-predict(fit4, newdata = ndata, interval = "prediction")
# Compare predictions
prds<-data.frame(p1=p1, p2=p2, p3=p3, p4=p4)
fits<-data.frame(p1=mean(prds$p1.fit),p2=mean(prds$p2.fit),p3=mean(prds$p3.fit),p4=mean(prds$p4.fit))
lwrs<-data.frame(p1=mean(prds$p1.lwr),p2=mean(prds$p2.lwr),p3=mean(prds$p3.lwr),p4=mean(prds$p4.lwr))
uprs<-data.frame(p1=mean(prds$p1.upr),p2=mean(prds$p2.upr),p3=mean(prds$p3.upr),p4=mean(prds$p4.upr))
ovrl<-rbind(fits, lwrs, uprs)
row.names(ovrl)<-c("fits", "lwr", "upr")
ovrl
cor(mtcars,use = "complete.obs", method = "kendall")
pairs(mpg~.,data = mtcars)
cor(mtcars,use = "complete.obs", method = "kendall")
head(mtcars)
pairs(mpg~cyl+disp+hp,data = mtcars)
pairs(mpg~cyl+disp+hp+wt,data = mtcars)
pairs(mpg~cyl+disp+hp+wt,data = mtcars)
fit1<-lm(mpg~factor(cyl) -1, data = auto)
fit1
summary(fit1)
fit2<-lm(mpg~factor(cyl)+wt -1, data = auto)
summary(fit2)
fit3<-lm(mpg~factor(cyl)+wt+disp -1, data = auto)
summary(fit3)
fit4<-lm(mpg~factor(cyl)+wt+disp+hp -1, data = auto)
summary(fit4)
anova(fit1, fit2, fit3, fit4)
fit1<-lm(mpg~factor(cyl), data = auto)
summary(fit1)
summarise(group_by(auto, cyl), meanMPG=mean(mpg))
# 2.2 MPG as an outcome, number of cylinders and weight as predictor variables
fit2<-lm(mpg~factor(cyl)+wt, data = auto)
summary(fit2)
# 2.3 MPG as an outcome, number of cylinders, weight, and displacement as predictor variables
fit3<-lm(mpg~factor(cyl)+wt+disp, data = auto)
summary(fit3)
# 2.4 MPG as an outcome, number of cylinders, weight, displacement and gross horsepower as predictor variables
fit4<-lm(mpg~factor(cyl)+wt+disp+hp, data = auto)
summary(fit4)
anova(fit1, fit2, fit3, fit4)
fit1<-lm(mpg~factor(cyl), data = auto)
summary(fit1)sigma
fit1<-lm(mpg~factor(cyl), data = auto)
summary(fit1)$sigma
fit1<-lm(mpg~factor(cyl), data = auto)
summary(fit1)$r.squared
fit1<-lm(mpg~factor(cyl), data = auto)
summary(fit1)
summary(fit1)$r.squared
anova(fit1, fit2, fit3, fit4)
shapiro.test(fit2$residuals)
shapiro.test(fit3$residuals)
shapiro.test(fit4$residuals)
fit1<-lm(Fertility~ Agriculture, data = swiss)
fit3<-lm(Fertility~Agriculture+Examination+Education, data = swiss)
anova(fit1, fit3)
deviance(fit3)
d<-deviance(fit3)/43 # 43 here is the degree of freedom of second model
n<-(deviance(fit1)-deviance(fit3))/2 # 2 is the value of degree of freedom model 1 minus that of model 2, 45-43=2.
Fvalue<-n/d
Fvalue
shapiro.test(fit3$residuals)
anova(fit1, fit2, fit3, fit4)
shapiro.test(fit2$residuals)
shapiro.test(fit3$residuals)
shapiro.test(fit4$residuals)
fit1<-lm(mpg~factor(cyl), data = auto)
summary(fit1)$r.squared
# MPG as an outcome, number of cylinders and weight as predictor variables
fit2<-lm(mpg~factor(cyl)+wt, data = auto)
summary(fit2)$r.squared
# MPG as an outcome, number of cylinders, weight, and displacement as predictor variables
fit3<-lm(mpg~factor(cyl)+wt+disp, data = auto)
summary(fit3)$r.squared
# MPG as an outcome, number of cylinders, weight, displacement and gross horsepower as predictor variables
fit4<-lm(mpg~factor(cyl)+wt+disp+hp, data = auto)
summary(fit4)$r.squared
anova(fit1, fit2, fit3, fit4)
shapiro.test(fit2$residuals)
shapiro.test(fit3$residuals)
shapiro.test(fit4$residuals)
c(deviance(fit1),deviance(fit2),deviance(fit3),deviance(fit4))
fit5<-lm(mpg~factor(cyl), data = manual)
summary(fit5)$r.squared
# MPG as an outcome, number of cylinders and weight as predictor variables
fit6<-lm(mpg~factor(cyl)+wt, data = manual)
summary(fit6)$r.squared
# MPG as an outcome, number of cylinders, weight and displacement as predictor variables
fit7<-lm(mpg~factor(cyl)+wt+disp, data = manual)
summary(fit7)$r.squared
# MPG as an outcome, number of cylinders, weight, displacement and gross horsepower as predictor variables
fit8<-lm(mpg~factor(cyl)+wt+disp+hp, data = manual)
summary(fit8)$r.squared
anova(fit5, fit6, fit7, fit8)
c(deviance(fit5),deviance(fit6),deviance(fit7),deviance(fit8))
shapiro.test(fit5$residuals)
shapiro.test(fit6$residuals)
shapiro.test(fit7$residuals)
shapiro.test(fit8$residuals)
anova(fit1, fit2, fit3, fit4)
c(deviance(fit1),deviance(fit2),deviance(fit3),deviance(fit4))
shapiro.test(fit2$residuals)
shapiro.test(fit3$residuals)
shapiro.test(fit4$residuals)
install.packages("readr")
library(magrittr)
?magritter
??magrittr
install.packages("oro.dicom")
library(oro.dicom)
?oro.dicom
library(caret)
args(trainControl)
suppressMessages(library(lattice))
suppressMessages(library(ggplot2))
suppressMessages(library(stats))
suppressMessages(library(dplyr))
setwd("~/Documents/Coursera/Practical Machine Learning/Blast Analysis")
train<-read.csv("test-dec.csv", header = TRUE)
train<-train[,-c(5:10)]
colnames(train)<-c("Cut.Length", "Rioprime.25", "UG.Matrix", "Blasted.Volume")
# First test set
test1<-read.csv("test.csv", header = TRUE)
test1<-na.omit(test1)
colnames(test1)<-c("Cut.Length", "Rioprime.25", "UG.Matrix", "Blasted.Volume")
# Second test set
test2<-read.csv("rdarfile2.csv", header = TRUE)
test2<-test2[,c(-1,-2,-11,-12,-16)]
test2<-na.omit(test2)
colnames(test2)<-c("Log.File", "Chainage", "Num.Holes", "Drill.Time", "Meter.Adv", "Cut.Length", "Plan.Length", "Overbreak", "Rioprime.25", "UG.Matrix", "Blasted.Volume")
head(train)
mean(train$Blasted.Volume)
sd(train$Blasted.Volume)
sd(train$Blasted.Volume)/mean(train$Blasted.Volume)
data("spam")
library(kernlab)
data("spam")
mean(spam$capitalAve)
sd(spam$capitalAve)
mean(spam$capitalAve)
sd(spam$capitalAve)
capAve<-spam$capitalAve
capAveS<-(capAve-mean(capAve))/sd(capAve)
mean(capAves)
capAveS<-(capAve-mean(capAve))/sd(capAve)
mean(capAveS)
sd(capAveS)
